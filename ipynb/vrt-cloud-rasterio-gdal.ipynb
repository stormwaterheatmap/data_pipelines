{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Cloud-Optimized Geotiffs from tiles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that gdal is installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GDAL 3.6.3, released 2023/03/07\n"
     ]
    }
   ],
   "source": [
    "!gdalinfo --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "import subprocess\n",
    "import json \n",
    "import pandas as pd\n",
    "from google.cloud import storage\n",
    "import os\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GS_NO_SIGN_REQUEST'] = 'YES'\n",
    "os.environ['GDAL_NUM_THREADS'] = 'ALL_CPUS'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log in to google cloud if needed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=32555940559.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8085%2F&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&state=VyOXZ5V8gPMkYZP6mD9Z7YuzWnhidI&access_type=offline&code_challenge=iumn1jETg_zGLsaheAEjVofEZZnGFSReH6xDxgJ_SjU&code_challenge_method=S256\n",
      "\n",
      "\n",
      "Application default credentials (ADC) were updated.\n",
      "\n",
      "You are now logged in as [cnilsen@gmail.com].\n",
      "Your current project is [swhm-dev].  You can change this setting by running:\n",
      "  $ gcloud config set project PROJECT_ID\n"
     ]
    }
   ],
   "source": [
    "#!{gcloud auth login --update-adc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "!{gcloud config set project swhm-dev}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "A function to list blobs on the storage bucket "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def list_blobs_with_prefix(bucket_name, prefix, delimiter=None):\n",
    "    \"\"\"Lists all the blobs in the bucket that begin with the prefix.\n",
    "    \"\"\"\n",
    "    storage_client = storage.Client()\n",
    "   \n",
    "    blobs = storage_client.list_blobs(bucket_name, prefix=prefix, delimiter=delimiter)\n",
    "\n",
    "    # Note: The call returns a response only when the iterator is consumed.\n",
    "    blob_list = []\n",
    "    for blob in blobs:\n",
    "        blob_list.append(blob.name)\n",
    "\n",
    "    if delimiter:\n",
    "        print(\"Prefixes:\")\n",
    "        for prefix in blobs.prefixes:\n",
    "            blob_list.append([prefix])\n",
    "    \n",
    "    return blob_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Download images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dl(lay_name):\n",
    "    cmd = f'gsutil -m cp -R gs://swhm-image-exports/{lay_name} .'\n",
    "    !{cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Reproject images\n",
    "\n",
    "saves reprojected images to /tmp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproject(lay_name, target_crs='EPSG:3857'): \n",
    "\n",
    "    directory_path = lay_name\n",
    "               #make a list of the files in the directory \n",
    "    files = os.listdir(directory_path+\"/reprojected\")\n",
    "    print(files)\n",
    "    # create a new file for writing\n",
    "    list_file = \"files.txt\"\n",
    "    try:\n",
    "        os.remove(list_file)\n",
    "    except OSError:\n",
    "        pass\n",
    "    \n",
    "    for filename in files:\n",
    "        if filename.endswith(\".tif\"):\n",
    "            input_path = os.path.join(directory_path, filename)\n",
    "            output_path = os.path.join(directory_path+\"/reprojected\", filename)\n",
    "            cmd = f'gdalwarp -t_srs {target_crs} -overwrite {input_path} {output_path}'\n",
    "            !{cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cmd = f'gdalwarp -t_srs \"EPSG:3857\"-overwrite runoff_testing.tif testing_translate.tif'\n",
    "# !{cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def write_file_list(lay_name):\n",
    "#     directory_path = lay_name\n",
    "#     files = os.listdir(directory_path)\n",
    "# # create a new file for writing\n",
    "#     list_file = \"files.txt\"\n",
    "#     try:\n",
    "#         os.remove(list_file)\n",
    "#     except OSError:\n",
    "#         pass\n",
    "            \n",
    "    \n",
    "#     with open(\"files.txt\", \"w\") as file:\n",
    "#         # write each file name to the file\n",
    "#         for f in files:\n",
    "#             if f.endswith(\".tif\"):\n",
    "#                 file.write(directory_path+\"/reprojected/\"+f + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build vrt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://gdal.org/programs/gdal_translate.html\n",
    "#cmdoption-gdal_translate-ovr\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# def makecog(): \n",
    "#     print('Making COG..')\n",
    "#     # cmd = f'''\n",
    "#     # gdal_translate output.vrt cog.tif -of COG -co NUM_THREADS=ALL_CPUS -co COMPRESS=LZW -co BIGTIFF=YES\n",
    "#     # '''\n",
    "#     cmd = f'''\n",
    "#     gdal_translate output.vrt cog2.tif -ot Float6 -of COG -r average \n",
    "#     -co COMPRESS=LZW -co BIGTIFF=YES -co TILING_SCHEME=GoogleMapsCompatible\n",
    "#     '''\n",
    "\n",
    "#     !{cmd}\n",
    "#     print('COG Complete!')\n",
    "    \n",
    "    \n",
    "# def makecog_rio(): \n",
    "#     print('Making COG..')\n",
    "\n",
    "#     cmd = f'''\n",
    "#     rio cogeo create output.vrt vrt_cog.tif --cog-profile lzw --config CHECK_DISK_FREE_SPACE=FALSE --overview-resampling average --allow-intermediate-compression'''\n",
    "\n",
    "#     !{cmd}\n",
    "#     print('COG Complete!')\n",
    "    \n",
    "# def make_geotiff():\n",
    "#     print('Making Geotiff') \n",
    "#     cmd = f'gdal_translate output.vrt gtiff.tif -ot Float64 -of GTiff -r average -co COMPRESS=LZW' \n",
    "#     !{cmd}\n",
    "#     print('Geotiff Complete!') \n",
    "# def ul(lay_name):\n",
    "#     print('Uploading Layer...')\n",
    "#     cmd = f'gsutil cp cog.tif gs://live_data_layers/rasters/{lay_name}.tif'\n",
    "#     !{cmd}\n",
    "#     print('Layer upload complete!') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://gdal.org/programs/gdal_translate.html\n",
    "#cmdoption-gdal_translate-ovr\n",
    "\n",
    "def makevrt(lay_name):\n",
    "    directory_path = lay_name+'/*.tif'\n",
    "    print('Making VRT...')\n",
    "    cmd = f'gdalbuildvrt  output.vrt {directory_path}'\n",
    "    !{cmd}\n",
    "    print('VRT Complete!')\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "# def make_geotiff():\n",
    "#     print('Making Geotiff') \n",
    "#     cmd = f'gdal_translate output.vrt gtiff.tif -ot Float64 -of GTiff -r average -co COMPRESS=LZW' \n",
    "#     !{cmd}\n",
    "#     print('Geotiff Complete!') \n",
    "def ul(lay_name):\n",
    "    print('Uploading Layer...')\n",
    "    cmd = f'gsutil cp {lay_name}_cog.tif gs://live_data_layers/rasters/{lay_name}.tif'\n",
    "    !{cmd}\n",
    "    print('Layer upload complete!') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def makecog(): \n",
    "#     print('Making COG..')\n",
    "#     # cmd = f'''\n",
    "#     # gdal_translate output.vrt cog.tif -of COG -co NUM_THREADS=ALL_CPUS -co COMPRESS=LZW -co BIGTIFF=YES\n",
    "#     # '''\n",
    "#     cmd = f'''\n",
    "#     gdal_translate output.vrt cog_gdal.tif \\\n",
    "#     -stats \\\n",
    "#     -ot Float64 -of COG \\\n",
    "#     -co COMPRESS=LZW -co BIGTIFF=YES \\\n",
    "#     -co TILED=YES\n",
    "#     -co OVERVIEWS=ignore_existing\n",
    "#     '''\n",
    "#     #-co TILING_SCHEME=GoogleMapsCompatible \n",
    "#     # -r average -a_nodata -9999\\\n",
    "#     #'''\n",
    "\n",
    "#     !{cmd}\n",
    "#     print('COG Complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you experience problems with multiprocessing on MacOS, they might be related to https://bugs.python.org/issue33725. You can disable multiprocessing by editing your .boto config or by adding the following flag to your command: `-o \"GSUtil:parallel_process_count=1\"`. Note that multithreading is still available even if you disable multiprocessing.\n",
      "\n",
      "Copying gs://swhm-image-exports/Precipitation_mm/Precipitation_mm.tif...\n",
      "/ [1/1 files][347.9 KiB/347.9 KiB] 100% Done                                    \n",
      "Operation completed over 1 objects/347.9 KiB.                                    \n",
      "Making VRT...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "VRT Complete!\n"
     ]
    }
   ],
   "source": [
    "# lay_name = 'Precipitation_mm' \n",
    "# dl(lay_name)\n",
    "# makevrt(lay_name)\n",
    "\n",
    "# cmd1 = '''\n",
    "# gdal_translate output.vrt tmp.tif \\\n",
    "# -co TILED=YES -co COMPRESS=LZW -co BIGTIFF=YES\n",
    "# '''\n",
    "# #cmd2 = 'gdaladdo -clean tmp.tif' \n",
    "# cmd3 = 'gdaladdo -r average tmp.tif' \n",
    "# cmd4 = f'''gdal_translate tmp.tif {lay_name}_cog.tif \\\n",
    "# -co TILED=YES -co COMPRESS=LZW -co COPY_SRC_OVERVIEWS=YES \\\n",
    "# -co BIGTIFF=YES\n",
    "# '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR 1: Translating source or target SRS failed:\n",
      "SR-ORG:6627\n",
      "Usage: gdalwarp [--help-general] [--formats]\n",
      "    [-s_srs srs_def] [-t_srs srs_def] [-to \"NAME=VALUE\"]* [-vshift | -novshift]\n",
      "    [[-s_coord_epoch epoch] | [-t_coord_epoch epoch]]\n",
      "    [-order n | -tps | -rpc | -geoloc] [-et err_threshold]\n",
      "    [-refine_gcps tolerance [minimum_gcps]]\n",
      "    [-te xmin ymin xmax ymax] [-tr xres yres] [-tap] [-ts width height]\n",
      "    [-ovr level|AUTO|AUTO-n|NONE] [-wo \"NAME=VALUE\"] [-ot Byte/Int16/...] [-wt Byte/Int16]\n",
      "    [-srcnodata \"value [value...]\"] [-dstnodata \"value [value...]\"] -dstalpha\n",
      "    [-r resampling_method] [-wm memory_in_mb] [-multi] [-q]\n",
      "    [-cutline datasource] [-cl layer] [-cwhere expression]\n",
      "    [-csql statement] [-cblend dist_in_pixels] [-crop_to_cutline]\n",
      "    [-if format]* [-of format] [-co \"NAME=VALUE\"]* [-overwrite]\n",
      "    [-nomd] [-cvmd meta_conflict_value] [-setci] [-oo NAME=VALUE]*\n",
      "    [-doo NAME=VALUE]*\n",
      "    srcfile* dstfile\n",
      "\n",
      "Available resampling methods:\n",
      "    near (default), bilinear, cubic, cubicspline, lanczos, average, rms,\n",
      "    mode,  max, min, med, Q1, Q3, sum.\n"
     ]
    }
   ],
   "source": [
    "# cmd = 'gdalwarp -t_srs SR-ORG:6627 output.vrt tmpwarped.tif'\n",
    "# !{cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file size is 380, 363\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n"
     ]
    }
   ],
   "source": [
    "!{cmd1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n"
     ]
    }
   ],
   "source": [
    "!{cmd3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file size is 380, 363\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n"
     ]
    }
   ],
   "source": [
    "!{cmd4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def makecog_rio(): \n",
    "#     print('Making COG with rio..')\n",
    "\n",
    "#     cmd = f'''\n",
    "#     rio cogeo create output.vrt vrt_cog.tif \\\n",
    "#     --resampling average --add-mask \\\n",
    "#     --cog-profile lzw --web-optimized \\\n",
    "#     --config CHECK_DISK_FREE_SPACE=FALSE \\\n",
    "#     --allow-intermediate-compression \\\n",
    "#     --blocksize 256 \n",
    "#     '''\n",
    "\n",
    "#     !{cmd}\n",
    "#     print('COG Complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Wrapper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_layer(lay_name): \n",
    "\n",
    "    #dl(lay_name)\n",
    "    \n",
    "    #Make a vrt of the downloaded images \n",
    "    makevrt(lay_name)\n",
    "    \n",
    "    #check projection \n",
    "    p = subprocess.run([\"rio\", \"info\", \"output.vrt\"], capture_output=True, text=True)\n",
    "    raster_info = json.loads(p.stdout)\n",
    "\n",
    "#reproject if needed \n",
    "    if (raster_info['crs']) != \"EPSG:3857\": \n",
    "        #reproject \n",
    "        print(f'reprojecting from {raster_info[\"crs\"]}')\n",
    "        warp_cmd = 'gdalwarp -t_srs EPSG:3857 -overwrite output.vrt tmp-reproj.tif \\\n",
    "         -co NUM_THREADS=5 -co TILED=YES -co COMPRESS=LZW -co BIGTIFF=YES --config CHECK_DISK_FREE_SPACE FALSE'\n",
    "        !{warp_cmd}\n",
    "        !{'mv tmp-reproj.tif tmp.tif'}\n",
    "\n",
    "            #rebuild pyramids if needed \n",
    "        #check data type\n",
    "        if (raster_info[\"dtype\"] != 'uint8'): \n",
    "            print(f'rebuilding overviews') \n",
    "            !{'gdaladdo -r average tmp.tif'}\n",
    "        \n",
    "    \n",
    "    if(raster_info[\"dtype\"] == \"uint8\" and raster_info['crs'] == \"EPSG:3857\"):\n",
    "        print('translating output.vrt') \n",
    "        translate_cmd = f'gdal_translate output.vrt {lay_name}_cog.tif \\\n",
    "        -co TILED=YES -co COMPRESS=LZW -co COPY_SRC_OVERVIEWS=YES \\\n",
    "        -co BIGTIFF=YES \\\n",
    "         -co NUM_THREADS=5 -co TILED=YES --config CHECK_DISK_FREE_SPACE FALSE'\n",
    "        !{translate_cmd}\n",
    "    else:\n",
    "        print('translating tmp.tif') \n",
    "        translate_cmd = f'gdal_translate tmp.tif {lay_name}_cog.tif \\\n",
    "        -co TILED=YES -co COMPRESS=LZW -co COPY_SRC_OVERVIEWS=YES \\\n",
    "        -co BIGTIFF=YES \\\n",
    "         -co NUM_THREADS=5 -co TILED=YES --config CHECK_DISK_FREE_SPACE FALSE'\n",
    "        !{translate_cmd}\n",
    "\n",
    "        \n",
    "\n",
    "           \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making VRT...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "VRT Complete!\n",
      "translating tmp.tif\n",
      "Input file size is 320651, 306809\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n"
     ]
    }
   ],
   "source": [
    "convert_layer(\"Precipitation_mm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading Layer...\n",
      "Copying file://Precipitation_mm_cog.tif [Content-Type=image/tiff]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run          \n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "/ [1 files][  2.2 GiB/  2.2 GiB]  621.6 KiB/s                                   \n",
      "Operation completed over 1 objects/2.2 GiB.                                      \n",
      "Layer upload complete!\n"
     ]
    }
   ],
   "source": [
    "ul(\"Precipitation_mm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #         print('doubs') \n",
    "# #         !{'gdaladdo -r average tmp.tif'} \n",
    "# def make_cog(lay_name):\n",
    "#     cog_command = f'''gdal_translate tmp.tif {lay_name}_cog.tif \\\n",
    "#     -co TILED=YES -co COMPRESS=LZW -co COPY_SRC_OVERVIEWS=YES \\\n",
    "#     -co BIGTIFF=YES\n",
    "#     '''\n",
    "#     !{cog_command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making VRT...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "VRT Complete!\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m lay_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecipitation_mm\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mconvert_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlay_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[70], line 24\u001b[0m, in \u001b[0;36mconvert_layer\u001b[0;34m(lay_name)\u001b[0m\n\u001b[1;32m     21\u001b[0m     get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmv tmp-reproj.tif tmp.tif\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#check data type\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[43mraster_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muint8\u001b[39m\u001b[38;5;124m'\u001b[39m): \n\u001b[1;32m     25\u001b[0m     get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgdaladdo -r average tmp.tif\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": [
    "# lay_name = \"Precipitation_mm\"\n",
    "\n",
    "# convert_layer(lay_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# p = subprocess.run([\"rio\", \"info\", \"output.vrt\"], capture_output=True, text=True)\n",
    "# raster_info = json.loads(p.stdout)\n",
    "# raster_info[\"dtype\"]\n",
    "# raster_info['crs']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating output file that is 320651P x 306809L.\n",
      "Processing output.vrt [1/1] : 0...10.^C\n"
     ]
    }
   ],
   "source": [
    "# warp_cmd = 'gdalwarp -t_srs EPSG:3857 -overwrite output.vrt tmp-reproj2.tif \\\n",
    "#          -co NUM_THREADS=5 -co TILED=YES -co COMPRESS=LZW -co BIGTIFF=YES --config CHECK_DISK_FREE_SPACE FALSE'\n",
    "# !{warp_cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Byte'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# raster = gdal.Open('output.vrt')\n",
    "# band = raster.GetRasterBand(1)\n",
    "# data_type = gdal.GetDataTypeName(band.DataType)\n",
    "# data_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Open the file and check type \n",
    "# raster = gdal.Open('tmp.tif')\n",
    "# band = raster.GetRasterBand(1)\n",
    "# data_type = gdal.GetDataTypeName(band.DataType)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file size is 320651, 306809\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n"
     ]
    }
   ],
   "source": [
    "# # Build command \n",
    "# lay_name = \"Land_Cover\"\n",
    "# cog_command = f'''gdal_translate tmp.tif {lay_name}_cog2.tif \\\n",
    "# -co TILED=YES -co COMPRESS=LZW -co COPY_SRC_OVERVIEWS=YES \\\n",
    "# -co BIGTIFF=YES -co NUM_THREADS=5 --config GDALSetCacheMax64 2'''\n",
    "# cog_command\n",
    "# !{cog_command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Byte\n",
      "reprojecting from EPSG:26910\n",
      "Creating output file that is 320651P x 306809L.\n",
      "Processing tmp.tif [1/1] : 0...10...20...30...40...50...60...70...80...90...100 - done.\n"
     ]
    }
   ],
   "source": [
    "# lay_name = \"Land_Cover\"\n",
    "# raster = gdal.Open('tmp.tif')\n",
    "# band = raster.GetRasterBand(1)\n",
    "# data_type = gdal.GetDataTypeName(band.DataType)\n",
    "# print(data_type)\n",
    "\n",
    "# #check projection \n",
    "# p = subprocess.run([\"rio\", \"info\", \"tmp.tif\"], capture_output=True, text=True)\n",
    "# raster_info = json.loads(p.stdout)\n",
    "\n",
    "# if (raster_info['crs']) != \"EPSG:3857\": \n",
    "#     #reproject \n",
    "#     print(f'reprojecting from {raster_info[\"crs\"]}')\n",
    "#     warp_cmd = 'gdalwarp -t_srs EPSG:3857 -overwrite  tmp.tif tmp-reproj.tif \\\n",
    "#     -co TILED=YES -co COMPRESS=LZW  -co BIGTIFF=YES -co NUM_THREADS=4'\n",
    "#     !{warp_cmd}\n",
    "#     #rename it and move on\n",
    "#     !{\"mv tmp-reproj.tif tmp.tif\"}\n",
    "\n",
    "# if data_type ==\"Double\": \n",
    "#     print('doubs') \n",
    "#     !{'gdaladdo -r average tmp.tif'} \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0Warning 1: Land_Cover_cog.tif: Adding new overviews invalidates the LAYOUT=IFDS_BEFORE_DATA property\n",
      "...10...20...30...40...50.^C\n"
     ]
    }
   ],
   "source": [
    "# !{'gdaladdo -r average Land_Cover_cog.tif'} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get list of objects in data bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = 'swhm-image-exports'\n",
    "blobsout = list_blobs_with_prefix(BUCKET_NAME,'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>gdal_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Flow_Duration_Index/Flow_Duration_Index0000000...</td>\n",
       "      <td>Flow_Duration_Index/Flow_Duration_Index0000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flow_Duration_Index/Flow_Duration_Index0000000...</td>\n",
       "      <td>Flow_Duration_Index/Flow_Duration_Index0000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Flow_Duration_Index/Flow_Duration_Index0000000...</td>\n",
       "      <td>Flow_Duration_Index/Flow_Duration_Index0000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Flow_Duration_Index/Flow_Duration_Index0000000...</td>\n",
       "      <td>Flow_Duration_Index/Flow_Duration_Index0000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Flow_Duration_Index/Flow_Duration_Index0000000...</td>\n",
       "      <td>Flow_Duration_Index/Flow_Duration_Index0000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>tss/tss0000023296-0000023296.tif</td>\n",
       "      <td>tss/tss0000023296-0000023296.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>zinc/zinc0000000000-0000000000.tif</td>\n",
       "      <td>zinc/zinc0000000000-0000000000.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>zinc/zinc0000000000-0000023296.tif</td>\n",
       "      <td>zinc/zinc0000000000-0000023296.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>zinc/zinc0000023296-0000000000.tif</td>\n",
       "      <td>zinc/zinc0000023296-0000000000.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>zinc/zinc0000023296-0000023296.tif</td>\n",
       "      <td>zinc/zinc0000023296-0000023296.tif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            file_path  \\\n",
       "0   Flow_Duration_Index/Flow_Duration_Index0000000...   \n",
       "1   Flow_Duration_Index/Flow_Duration_Index0000000...   \n",
       "2   Flow_Duration_Index/Flow_Duration_Index0000000...   \n",
       "3   Flow_Duration_Index/Flow_Duration_Index0000000...   \n",
       "4   Flow_Duration_Index/Flow_Duration_Index0000000...   \n",
       "..                                                ...   \n",
       "80                   tss/tss0000023296-0000023296.tif   \n",
       "81                 zinc/zinc0000000000-0000000000.tif   \n",
       "82                 zinc/zinc0000000000-0000023296.tif   \n",
       "83                 zinc/zinc0000023296-0000000000.tif   \n",
       "84                 zinc/zinc0000023296-0000023296.tif   \n",
       "\n",
       "                                            gdal_path  \n",
       "0   Flow_Duration_Index/Flow_Duration_Index0000000...  \n",
       "1   Flow_Duration_Index/Flow_Duration_Index0000000...  \n",
       "2   Flow_Duration_Index/Flow_Duration_Index0000000...  \n",
       "3   Flow_Duration_Index/Flow_Duration_Index0000000...  \n",
       "4   Flow_Duration_Index/Flow_Duration_Index0000000...  \n",
       "..                                                ...  \n",
       "80                   tss/tss0000023296-0000023296.tif  \n",
       "81                 zinc/zinc0000000000-0000000000.tif  \n",
       "82                 zinc/zinc0000000000-0000023296.tif  \n",
       "83                 zinc/zinc0000023296-0000000000.tif  \n",
       "84                 zinc/zinc0000023296-0000023296.tif  \n",
       "\n",
       "[85 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(blobsout, columns=['file_path'])#.iloc[1:]\n",
    "#df['folder_name'] = df['file_path'].str.split(BUCKET_NAME, 1,expand = True)\n",
    "df['gdal_path'] = df['file_path'].str.replace('gs://', '/vsigs/') \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yn/15903z7124l3th5fm7wg0lgw0000gn/T/ipykernel_4889/3619429793.py:1: FutureWarning: In a future version of pandas all arguments of StringMethods.split except for the argument 'pat' will be keyword-only.\n",
      "  lay_names= df['file_path'].str.split('/', 0).str[0]#.str.replace('/','',regex=False)\n",
      "/var/folders/yn/15903z7124l3th5fm7wg0lgw0000gn/T/ipykernel_4889/3619429793.py:2: FutureWarning: In a future version of pandas all arguments of StringMethods.split except for the argument 'pat' will be keyword-only.\n",
      "  df['layer_name'] = lay_names.str.split('/',1).str[0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>gdal_path</th>\n",
       "      <th>layer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Flow_Duration_Index/Flow_Duration_Index0000000...</td>\n",
       "      <td>Flow_Duration_Index/Flow_Duration_Index0000000...</td>\n",
       "      <td>Flow_Duration_Index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flow_Duration_Index/Flow_Duration_Index0000000...</td>\n",
       "      <td>Flow_Duration_Index/Flow_Duration_Index0000000...</td>\n",
       "      <td>Flow_Duration_Index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Flow_Duration_Index/Flow_Duration_Index0000000...</td>\n",
       "      <td>Flow_Duration_Index/Flow_Duration_Index0000000...</td>\n",
       "      <td>Flow_Duration_Index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Flow_Duration_Index/Flow_Duration_Index0000000...</td>\n",
       "      <td>Flow_Duration_Index/Flow_Duration_Index0000000...</td>\n",
       "      <td>Flow_Duration_Index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Flow_Duration_Index/Flow_Duration_Index0000000...</td>\n",
       "      <td>Flow_Duration_Index/Flow_Duration_Index0000000...</td>\n",
       "      <td>Flow_Duration_Index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>tss/tss0000023296-0000023296.tif</td>\n",
       "      <td>tss/tss0000023296-0000023296.tif</td>\n",
       "      <td>tss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>zinc/zinc0000000000-0000000000.tif</td>\n",
       "      <td>zinc/zinc0000000000-0000000000.tif</td>\n",
       "      <td>zinc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>zinc/zinc0000000000-0000023296.tif</td>\n",
       "      <td>zinc/zinc0000000000-0000023296.tif</td>\n",
       "      <td>zinc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>zinc/zinc0000023296-0000000000.tif</td>\n",
       "      <td>zinc/zinc0000023296-0000000000.tif</td>\n",
       "      <td>zinc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>zinc/zinc0000023296-0000023296.tif</td>\n",
       "      <td>zinc/zinc0000023296-0000023296.tif</td>\n",
       "      <td>zinc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            file_path  \\\n",
       "0   Flow_Duration_Index/Flow_Duration_Index0000000...   \n",
       "1   Flow_Duration_Index/Flow_Duration_Index0000000...   \n",
       "2   Flow_Duration_Index/Flow_Duration_Index0000000...   \n",
       "3   Flow_Duration_Index/Flow_Duration_Index0000000...   \n",
       "4   Flow_Duration_Index/Flow_Duration_Index0000000...   \n",
       "..                                                ...   \n",
       "80                   tss/tss0000023296-0000023296.tif   \n",
       "81                 zinc/zinc0000000000-0000000000.tif   \n",
       "82                 zinc/zinc0000000000-0000023296.tif   \n",
       "83                 zinc/zinc0000023296-0000000000.tif   \n",
       "84                 zinc/zinc0000023296-0000023296.tif   \n",
       "\n",
       "                                            gdal_path           layer_name  \n",
       "0   Flow_Duration_Index/Flow_Duration_Index0000000...  Flow_Duration_Index  \n",
       "1   Flow_Duration_Index/Flow_Duration_Index0000000...  Flow_Duration_Index  \n",
       "2   Flow_Duration_Index/Flow_Duration_Index0000000...  Flow_Duration_Index  \n",
       "3   Flow_Duration_Index/Flow_Duration_Index0000000...  Flow_Duration_Index  \n",
       "4   Flow_Duration_Index/Flow_Duration_Index0000000...  Flow_Duration_Index  \n",
       "..                                                ...                  ...  \n",
       "80                   tss/tss0000023296-0000023296.tif                  tss  \n",
       "81                 zinc/zinc0000000000-0000000000.tif                 zinc  \n",
       "82                 zinc/zinc0000000000-0000023296.tif                 zinc  \n",
       "83                 zinc/zinc0000023296-0000000000.tif                 zinc  \n",
       "84                 zinc/zinc0000023296-0000023296.tif                 zinc  \n",
       "\n",
       "[85 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lay_names= df['file_path'].str.split('/', 0).str[0]#.str.replace('/','',regex=False)\n",
    "df['layer_name'] = lay_names.str.split('/',1).str[0]\n",
    "df\n",
    "#lay_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Flow_Duration_Index', 'Land_Cover', 'Land_Use', 'Slope', 'Soils',\n",
       "       'copper', 'p', 'tkn', 'tss', 'zinc'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lay_names = df[\"layer_name\"].unique()\n",
    "lay_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "its a byte\n"
     ]
    }
   ],
   "source": [
    "filepath = 'Land_Cover/Land_Cover0000000000-0000000000.tif'\n",
    "# Open the file:\n",
    "raster = gdal.Open(filepath)\n",
    "band = raster.GetRasterBand(1)\n",
    "data_type = gdal.GetDataTypeName(band.DataType)\n",
    "\n",
    "if data_type == 'Byte': \n",
    "    print('its a byte')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you experience problems with multiprocessing on MacOS, they might be related to https://bugs.python.org/issue33725. You can disable multiprocessing by editing your .boto config or by adding the following flag to your command: `-o \"GSUtil:parallel_process_count=1\"`. Note that multithreading is still available even if you disable multiprocessing.\n",
      "\n",
      "Copying gs://swhm-image-exports/Land_Cover/Land_Cover0000000000-0000000000.tif...\n",
      "Copying gs://swhm-image-exports/Land_Cover/Land_Cover0000000000-0000065536.tif...\n",
      "Copying gs://swhm-image-exports/Land_Cover/Land_Cover0000000000-0000131072.tif...\n",
      "Copying gs://swhm-image-exports/Land_Cover/Land_Cover0000000000-0000196608.tif...\n",
      "Copying gs://swhm-image-exports/Land_Cover/Land_Cover0000065536-0000065536.tif...\n",
      "Copying gs://swhm-image-exports/Land_Cover/Land_Cover0000065536-0000000000.tif...\n",
      "Copying gs://swhm-image-exports/Land_Cover/Land_Cover0000065536-0000131072.tif...\n",
      "Copying gs://swhm-image-exports/Land_Cover/Land_Cover0000000000-0000262144.tif...\n",
      "Copying gs://swhm-image-exports/Land_Cover/Land_Cover0000065536-0000196608.tif...\n",
      "Copying gs://swhm-image-exports/Land_Cover/Land_Cover0000065536-0000262144.tif...\n",
      "==> NOTE: You are downloading one or more large file(s), which would\n",
      "run significantly faster if you enabled sliced object downloads. This\n",
      "feature is enabled by default but requires that compiled crcmod be\n",
      "installed (see \"gsutil help crcmod\").\n",
      "\n",
      "Copying gs://swhm-image-exports/Land_Cover/Land_Cover0000196608-0000000000.tif...\n",
      "Copying gs://swhm-image-exports/Land_Cover/Land_Cover0000131072-0000065536.tif...\n",
      "Copying gs://swhm-image-exports/Land_Cover/Land_Cover0000262144-0000262144.tif...\n",
      "Copying gs://swhm-image-exports/Land_Cover/Land_Cover0000131072-0000196608.tif...\n",
      "Copying gs://swhm-image-exports/Land_Cover/Land_Cover0000131072-0000000000.tif...\n",
      "Copying gs://swhm-image-exports/Land_Cover/Land_Cover0000196608-0000131072.tif...\n",
      "Copying gs://swhm-image-exports/Land_Cover/Land_Cover0000196608-0000196608.tif...\n",
      "Copying gs://swhm-image-exports/Land_Cover/Land_Cover0000131072-0000262144.tif...\n",
      "Copying gs://swhm-image-exports/Land_Cover/Land_Cover0000196608-0000065536.tif...\n",
      "Copying gs://swhm-image-exports/Land_Cover/Land_Cover0000131072-0000131072.tif...\n",
      "Copying gs://swhm-image-exports/Land_Cover/Land_Cover0000262144-0000196608.tif...\n",
      "Copying gs://swhm-image-exports/Land_Cover/Land_Cover0000262144-0000000000.tif...\n",
      "Copying gs://swhm-image-exports/Land_Cover/Land_Cover0000262144-0000065536.tif...\n",
      "Copying gs://swhm-image-exports/Land_Cover/Land_Cover0000262144-0000131072.tif...\n",
      "Copying gs://swhm-image-exports/Land_Cover/Land_Cover0000196608-0000262144.tif...\n",
      "| [25/25 files][  2.3 GiB/  2.3 GiB] 100% Done  16.7 MiB/s ETA 00:00:00         \n",
      "Operation completed over 25 objects/2.3 GiB.                                     \n"
     ]
    }
   ],
   "source": [
    "dl(lay_names[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_pipeline('Runoff_mm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop through layer names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this to run the pipeline for all layers in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for lay_name in lay_names:\n",
    "    run_pipeline(lay_name) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "vscode": {
   "interpreter": {
    "hash": "3d597f4c481aa0f25dceb95d2a0067e73c0966dcbd003d741d821a7208527ecf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
